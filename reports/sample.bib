@INPROCEEDINGS{autocontrol,
  author={Xia, Wei and Li, Huiyun and Li, Baopu},
  booktitle={2016 9th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={A Control Strategy of Autonomous Vehicles Based on Deep Reinforcement Learning}, 
  year={2016},
  volume={2},
  number={},
  pages={198-201},
  keywords={Learning (artificial intelligence);Training;Neural networks;Automobiles;Roads;Autonomous vehicles;Autonomous vehicles;neural network;deep reinforcement learning},
  doi={10.1109/ISCID.2016.2054}}

@INPROCEEDINGS{mobilecontrol,
  author={Ruan, Xiaogang and Ren, Dingqi and Zhu, Xiaoqing and Huang, Jing},
  booktitle={2019 Chinese Control And Decision Conference (CCDC)}, 
  title={Mobile Robot Navigation based on Deep Reinforcement Learning}, 
  year={2019},
  volume={},
  number={},
  pages={6174-6178},
  keywords={Navigation;Robot sensing systems;Reinforcement learning;Deep learning;Mobile robots;Collision avoidance;Robot Navigation;Deep Reinforcement Learning;Depth Image},
  doi={10.1109/CCDC.2019.8832393}}

@INPROCEEDINGS{hottopic,
  author={D. Oliver Cann},
  booktitle={Media Relations World Economic Forum}, 
  title={These are the top 10 emerging technologies of 2016}, 
  year={2016},
  }

@online{waymo_data,
  title = {Waymo Open Dataset},
  author = {Waymo},
  year = {2024},
  url = {https://waymo.com/open},
  note = {Accessed: June 11, 2024}
}

@online{waymo,
  title = {Waymo},
  year = {2024},
  url = {https://waymo.com},
  note = {Accessed: June 11, 2024}
}

@online{tesla,
  title = {Tesla},
  year = {2024},
  url = {https://tesla.com},
  note = {Accessed: June 11, 2024}
}

@online{lds02,
  title = {LDS-02},
  year = {2024},
  url = {https://emanual.robotis.com/docs/en/platform/turtlebot3/appendix_lds_02/}
}

@online{camera,
  title = {Raspberry Pi Camera},
  year = {2024},
  url = {https://emanual.robotis.com/docs/en/platform/turtlebot3/appendix_raspi_cam/}
}

@online{encoders,
  title = {Encoder},
  year = {2024},
  url = {https://emanual.robotis.com/docs/en/platform/turtlebot3/appendixes/#more-info}
}


@Article{autonomous_review,
AUTHOR = {Parekh, Darsh and Poddar, Nishi and Rajpurkar, Aakash and Chahal, Manisha and Kumar, Neeraj and Joshi, Gyanendra Prasad and Cho, Woong},
TITLE = {A Review on Autonomous Vehicles: Progress, Methods and Challenges},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {14},
ARTICLE-NUMBER = {2162},
URL = {https://www.mdpi.com/2079-9292/11/14/2162},
ISSN = {2079-9292},
ABSTRACT = {Vehicular technology has recently gained increasing popularity, and autonomous driving is a hot topic. To achieve safe and reliable intelligent transportation systems, accurate positioning technologies need to be built to factor in the different types of uncertainties such as pedestrian behavior, random objects, and types of roads and their settings. In this work, we look into the other domains and technologies required to build an autonomous vehicle and conduct a relevant literature analysis. In this work, we look into the current state of research and development in environment detection, pedestrian detection, path planning, motion control, and vehicle cybersecurity for autonomous vehicles. We aim to study the different proposed technologies and compare their approaches. For a car to become fully autonomous, these technologies need to be accurate enough to gain public trust and show immense accuracy in their approach to solving these problems. Public trust and perception of auto vehicles are also explored in this paper. By discussing the opportunities as well as the obstacles of autonomous driving technology, we aim to shed light on future possibilities.},
DOI = {10.3390/electronics11142162}
}


@article{lidar_path_planning,
title = {A comprehensive survey of LIDAR-based 3D object detection methods with deep learning for autonomous driving},
journal = {Computers \& Graphics},
volume = {99},
pages = {153-181},
year = {2021},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2021.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0097849321001321},
author = {Georgios Zamanakos and Lazaros Tsochatzidis and Angelos Amanatiadis and Ioannis Pratikakis},
keywords = {3D Object detection, Deep learning, Autonomous driving},
abstract = {LiDAR-based 3D object detection for autonomous driving has recently drawn the attention of both academia and industry since it relies upon a sensor that incorporates appealing features like insensitivity to light and capacity to capture the 3D spatial structure of an object along with the continuous reduction of its purchase cost. Furthermore, the emergence of Deep Learning as the means to boost performance in 3D data analysis stimulated the production of a multitude of solutions for LIDAR-based 3D object detection which followed different approaches in an effort to respond effectively to several challenges. In view of this, this paper presents a comprehensive survey of LIDAR-based 3D object detection methods wherein an analysis of existing methods is addressed by taking into account a new categorisation that relies upon a common operational pipeline which describes the end-to-end functionality of each method. We next, discuss the existing benchmarking frameworks and present the performance achieved by each method in each of them. Finally, a discussion is presented that provides key insights aiming to capture the essence of current trends in LIDAR-based 3D object detection.}
}

@article{control_CNN,
author = {Nathan A. Spielberg  and Matthew Brown  and Nitin R. Kapania  and John C. Kegelman  and J. Christian Gerdes },
title = {Neural network vehicle models for high-performance automated driving},
journal = {Science Robotics},
volume = {4},
number = {28},
pages = {eaaw1975},
year = {2019},
doi = {10.1126/scirobotics.aaw1975},
URL = {https://www.science.org/doi/abs/10.1126/scirobotics.aaw1975},
eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.aaw1975},
abstract = {A neural network improved performance over a simple model when implemented in feedforward-feedback control on an experimental vehicle. Automated vehicles navigate through their environment by first planning and subsequently following a safe trajectory. To prove safer than human beings, they must ultimately perform these tasks as well or better than human drivers across a broad range of conditions and in critical situations. We show that a feedforward-feedback control structure incorporating a simple physics-based model can be used to track a path up to the friction limits of the vehicle with performance comparable with a champion amateur race car driver. The key is having the appropriate model. Although physics-based models are useful in their transparency and intuition, they require explicit characterization around a single operating point and fail to make use of the wealth of vehicle data generated by autonomous vehicles. To circumvent these limitations, we propose a neural network structure using a sequence of past states and inputs motivated by the physical model. The neural network achieved better performance than the physical model when implemented in the same feedforward-feedback control architecture on an experimental vehicle. More notably, when trained on a combination of data from dry roads and snow, the model was able to make appropriate predictions for the road surface on which the vehicle was traveling without the need for explicit road friction estimation. These findings suggest that the network structure merits further investigation as the basis for model-based control of automated vehicles over their full operating range.}}


@article{PPO_algo,
author = {Jin, Xin and Wang, Zhengxiao},
title = {Proximal policy optimization based dynamic path planning algorithm for mobile robots},
journal = {Electronics Letters},
volume = {58},
number = {1},
pages = {13-15},
keywords = {Computer communications, Mobile radio systems, Optimisation techniques, Spatial variables control, Mobile robots, Multiprocessing systems, Optimisation techniques, Parallel software, Operating systems},
doi = {https://doi.org/10.1049/ell2.12342},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/ell2.12342},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/ell2.12342},
abstract = {Abstract For the scenario where the overall layout is known and the obstacle distribution information is unknown, a dynamic path planning algorithm combining the A* algorithm and the proximal policy optimization (PPO) algorithm is proposed. Simulation experiments show that in all six test environments, the proposed algorithm finds paths that are on average about 2.04\% to 5.86\% shorter compared to the state-of-the-art algorithms in the literature, and reduces the number of training epochs before stabilization from tens of thousands to about 4000.},
year = {2022}
}

@article{SLAM,
author = {Wang, Xuanbo},
title = {Autonomous Mobile Robot Visual SLAM Based on Improved CNN Method},
journal = {IOP Conf. Ser.: Mater. Sci. Eng},
doi = {https://doi.org/10.1088/1757-899X/466/1/012114},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/ell2.12342},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/ell2.12342},
year = {2018}
}

@misc{scikit-learn-dbscan,
  title = {DBSCAN: Density-Based Spatial Clustering of Applications with Noise},
  author = {{Scikit-learn Developers}},
  year = {2024},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}},
  note = {Accessed: 14-Jun-2024}
}

@misc{KalmanFilter1D,
  author       = {David Wilson},
  title        = {The Kalman Filter: An Example of Using 1-D Filters},
  year         = {2024},
  howpublished = {\url{https://www.kalmanfilter.net/kalman1d.html}},
  note         = {Accessed: 2024-06-14}
}

@INPROCEEDINGS{yolo,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  year={2016},
  volume={},
  number={},
  pages={779-788},
  keywords={Computer architecture;Microprocessors;Object detection;Training;Real-time systems;Neural networks;Pipelines},
  doi={10.1109/CVPR.2016.91}}